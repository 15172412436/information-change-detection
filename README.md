# information-change-detection

​		目前，人们获取信息通常是借助搜索引擎进行检索，然后在返回的海量结果中筛选所需信息，但是互联网信息具有长期存在性和动态更新性，随着时间的推移搜索引擎返回的信息量越来越大，单纯靠人工进行信息的筛选和过滤，不仅效率低，且负担重。此外，互联网信息利用目前还是以被动式的查询方式为主，若用户想及时获取特定主题的第一手互联网资料，需时刻关注该主题的互联网信息更新情况，这便会浪费用户大量的时间和精力。虽然现在已有一些搜索引擎提供信息订阅功能，但大多都局限于某一个领域，不能满足于大多数人的需求。

​		因此，基于以上需求，本项目研究面向主题的互联网信息变化检测，帮助用户自动筛选特定主题的互联网信息，并实时追踪该主题的信息检索结果，提取变化信息（增量信息）主动推送用户，保证用户获取信息的高效性、及时性和便捷性。此外，本项目还对提取的变化信息进一步提炼热点话题，帮助用户了解特定主题在某一时期所谈论的重大事件，做到真正的“个性化”服务。本项目的研究一共分为三大模块，具体内容如下：

（1）**特定主题（检索字符串）的信息变化检测**。首先，为保证信息的查全率，利用元搜索引擎进行初始信息检索；然后，通过消除无效链接、去除重复结果、主题相关度计算方法对搜索结果进行筛选和过滤，在此期间，利用摘要算法计算结果信息与主题的相关度时，发现准确率较低，因此将主题权重与摘要算法结合计算结果相关度，提出了改进的摘要主题相关度算法(IAR)，该算法进一步提高了信息筛选准确率；最后，实时追踪特定主题的互联网信息，检测变化信息（增量信息），并提供主动式的信息推送服务。

（2）**针对提取的变化信息进行热点分析**。首先利用python自主编写爬虫程序实现主题变化信息的内容采集，然后利用正则表达式对采集内容进行预处理，接着利用jieba分词工具实现分词、去除停用词、词频统计等处理，最后将高频词汇以热点话题的形式自动推送用户。

（3）**特定网站的信息动态变化检测**。首先，利用Scrapy框架进行网站信息采集，并以域名来限制信息爬取范围。然后，通过set集合对重复链接进行消重处理，并利用IP代理防止网站反爬虫。最后，实时追踪该网站，检测网站变化信息（增量信息），并提供主动式的网站变化信息推送服务。